var documenterSearchIndex = {"docs":
[{"location":"measures.html","page":"Measures","title":"Measures","text":"CurrentModule = JudiLingMeasures","category":"page"},{"location":"measures.html","page":"Measures","title":"Measures","text":"Pages = [\"measures.md\"]","category":"page"},{"location":"measures.html#Measures","page":"Measures","title":"Measures","text":"","category":"section"},{"location":"measures.html","page":"Measures","title":"Measures","text":"This page contains documentation for all measures found in this package.","category":"page"},{"location":"measures.html","page":"Measures","title":"Measures","text":"Modules = [JudiLingMeasures]\nPages   = [\"measures.jl\"]\nOrder = [:module, :type, :function, :macro]","category":"page"},{"location":"measures.html#JudiLingMeasures.ALC-Tuple{Union{SparseArrays.SparseMatrixCSC, Matrix}}","page":"Measures","title":"JudiLingMeasures.ALC","text":"ALC(cor_s::Union{JudiLing.SparseMatrixCSC, Matrix})\n\nCompute the Average Lexical Correlation (ALC) between the predicted vectors in Shat and all semantic vectors in S.\n\nArguments\n\ns_cor::Union{JudiLing.SparseMatrixCSC, Matrix}: the correlation matrix between S and Shat\n\nExamples\n\njulia> Shat = [[1 2 1 1]; [1 -2 3 1]; [1 -2 3 3]; [0 0 1 2]]\njulia> S = [[-1 2 1 1]; [1 2 3 1]; [1 2 0 1]; [0.5 -2 1.5 0]]\njulia> acc, cor_s = JudiLing.eval_SC(Shat, S, R=true)\njulia> ALC(cor_s)\n4-element Vector{Float64}:\n  0.1867546970250672\n -0.030901103469572838\n -0.0681995247218424\n  0.011247813283240052\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.ALDC-Tuple{DataFrames.DataFrame}","page":"Measures","title":"JudiLingMeasures.ALDC","text":"ALDC(df::DataFrame)\n\nCompute the Average Levenshtein Distance of all candidates (ALDC) with the correct word form.\n\nArguments\n\ndf::DataFrame: DataFrame of the output of learn_paths.\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.EDNN-Tuple{Union{SparseArrays.SparseMatrixCSC, Matrix}, Union{SparseArrays.SparseMatrixCSC, Matrix}, Union{SparseArrays.SparseMatrixCSC, Matrix}}","page":"Measures","title":"JudiLingMeasures.EDNN","text":"EDNN(Shat::Union{JudiLing.SparseMatrixCSC, Matrix},\n     S::Union{JudiLing.SparseMatrixCSC, Matrix})\n\nCompute the Euclidean Distance nearest neighbours between the predicted semantic vectors in Shat and the semantic vectors in Sval and Strain.\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.EDNN-Tuple{Union{SparseArrays.SparseMatrixCSC, Matrix}, Union{SparseArrays.SparseMatrixCSC, Matrix}}","page":"Measures","title":"JudiLingMeasures.EDNN","text":"EDNN(Shat::Union{JudiLing.SparseMatrixCSC, Matrix},\n     S::Union{JudiLing.SparseMatrixCSC, Matrix})\n\nCompute the Euclidean Distance nearest neighbours between the predicted semantic vectors in Shat and the semantic vectors in S.\n\nExamples\n\nExamples\n\njulia> ma1 = [[1 2 3]; [-1 -2 -3]; [1 2 3]]\njulia> ma4 = [[1 2 2]; [1 -2 -3]; [0 2 3]]\njulia> EDNN(ma1, ma4)\n3-element Vector{Float64}:\n 1.0\n 2.0\n 1.0\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.L1Norm-Tuple{Union{SparseArrays.SparseMatrixCSC, Matrix}}","page":"Measures","title":"JudiLingMeasures.L1Norm","text":"L1Norm(M::Union{JudiLing.SparseMatrixCSC, Matrix})\n\nCompute the L1 Norm of each row of a matrix.\n\nExamples\n\njulia> Shat = [[1 2 3]; [-1 -2 -3]; [1 2 3]]\njulia> L1Norm(Shat)\n3-element Vector{Int64}:\n 6\n 6\n 6\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.L2Norm-Tuple{Union{SparseArrays.SparseMatrixCSC, Matrix}}","page":"Measures","title":"JudiLingMeasures.L2Norm","text":"L2Norm(M::Union{JudiLing.SparseMatrixCSC, Matrix})\n\nCompute the L2 Norm of each row of a matrix.\n\nExamples\n\njulia> Shat = [[1 2 3]; [-1 -2 -3]; [1 2 3]]\njulia> L2Norm(Shat)\n3-element Vector{Float64}:\n 3.7416573867739413\n 3.7416573867739413\n 3.7416573867739413\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.NNC-Tuple{Union{SparseArrays.SparseMatrixCSC, Matrix}}","page":"Measures","title":"JudiLingMeasures.NNC","text":"NNC(cor_s::Union{JudiLing.SparseMatrixCSC, Matrix})\n\nFor each predicted semantic vector get the highest correlation with the semantic vectors in S.\n\nArguments\n\ns_cor::Union{JudiLing.SparseMatrixCSC, Matrix}: the correlation matrix between S and Shat\n\nExamples\n\njulia> Shat = [[1 2 1 1]; [1 -2 3 1]; [1 -2 3 3]; [0 0 1 2]]\njulia> S = [[-1 2 1 1]; [1 2 3 1]; [1 2 0 1]; [0.5 -2 1.5 0]]\njulia> acc, cor_s = JudiLing.eval_SC(Shat, S, R=true)\njulia> NNC(cor_s)\n4-element Vector{Float64}:\n 0.8164965809277259\n 0.9886230654859615\n 0.8625383733289683\n 0.35478743759344955\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.SCPP-Tuple{DataFrames.DataFrame, DataFrames.DataFrame}","page":"Measures","title":"JudiLingMeasures.SCPP","text":"SCPP(df::DataFrame, results::DataFrame)\n\nSemantic Correlation of Predicted Production. Returns the correlation of the predicted semantic vector of the predicted path with the target semantic vector.\n\nArguments\n\ndf::DataFrame: The output of learn_paths as DataFrame.\nresults::DataFrame: The data of interest.\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.c_precision-Tuple{Any, Any}","page":"Measures","title":"JudiLingMeasures.c_precision","text":"c_precision(c_hat_collection, cue_obj)\n\nCalculate the correlation between the predicted and the target cue vector.\n\nExamples\n\njulia> c = [[1. 1. 0.]; [0. 0. 1.]; [1. 0. 1.]]\njulia> chat = [[0.9 0.9 0.1]; [0.9 0.1 1.]; [0.9 -0.1 0.8]]\njulia> c_precision(chat, c)\n3-element Array{Float64,1}:\n 1.0\n 0.5852057359806527\n 0.9958705948858222\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.density-Tuple{Union{SparseArrays.SparseMatrixCSC, Matrix}}","page":"Measures","title":"JudiLingMeasures.density","text":"density(cor_s::Union{JudiLing.SparseMatrixCSC, Matrix};\n        n::Int=8, ignore_missing::Bool=false)\n\nCompute the average correlation of each predicted semantic vector with its n most correlated neighbours.\n\nArguments\n\ns_cor::Union{JudiLing.SparseMatrixCSC, Matrix}: the correlation matrix between S and Shat\nn::Int: the number of highest semantic neighbours to take into account\n\nExample\n\njulia> Shat = [[1 2 1 1]; [1 -2 3 1]; [1 -2 3 3]; [0 0 1 2]]\njulia> S = [[-1 2 1 1]; [1 2 3 1]; [1 2 0 1]; [0.5 -2 1.5 0]]\njulia> acc, cor_s = JudiLing.eval_SC(Shat, S, R=true)\njulia> density(cor_s, n=2)\n4-element Vector{Float64}:\n 0.7393813797301239\n 0.6420816485652429\n 0.4496869233815781\n 0.281150888376636\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.functional_load-Tuple{Union{SparseArrays.SparseMatrixCSC, Matrix}, Union{SparseArrays.SparseMatrixCSC, Matrix}, JudiLing.Cue_Matrix_Struct}","page":"Measures","title":"JudiLingMeasures.functional_load","text":"function functional_load(F::Union{JudiLing.SparseMatrixCSC, Matrix},\n                         Shat::Union{JudiLing.SparseMatrixCSC, Matrix},\n                         cue_obj::JudiLing.Cue_Matrix_Struct;\n                         cue_list::Union{Vector{String}, Missing}=missing,\n                         method::Union{String, Symbol}=\"corr\")\n\nCorrelation/MSE of rows in F of triphones in word w and semantic vector of w.\n\nMeasure developed by Motoki Saito. Note: the current version of Functional Load is not completely tested against its original implementation in pyldl.\n\nArguments\n\nF::Union{JudiLing.SparseMatrixCSC, Matrix}: The comprehension matrix F\nShat::Union{JudiLing.SparseMatrixCSC, Matrix}: The predicted semantic matrix of the data of interest\ncueobj::JudiLing.CueMatrix_Struct: The cue object of the data of interest.\ncuelist::Union{Vector{String}, Missing}=missing: List of cues for which functional load should be computed. Each cue in the list corresponds to one word in Shat/cueobj and cue and corresponding words have to be in the same order.\nmethod::Union{String, Symbol}=\"corr\": If \"corr\", correlation between row in F and semantic vector in S is computed. If \"mse\", mean squared error is used.\n\nExample\n\njulia> using JudiLing, DataFrames, JudiLingMeasures\njulia> dat = DataFrame(\"Word\"=>[\"abc\", \"bcd\", \"cde\"]);\njulia> cue_obj = JudiLing.make_cue_matrix(dat, grams=3, target_col=:Word);\njulia> n_features = size(cue_obj.C, 2);\njulia> S = JudiLing.make_S_matrix(\n    dat,\n    [\"Word\"],\n    [],\n    ncol=n_features);\njulia> F = JudiLing.make_transform_matrix(cue_obj.C, S);\njulia> Shat = cue_obj.C * F;\njulia> JudiLingMeasures.functional_load(F, Shat, cue_obj)\n3-element Vector{Any}:\n [0.9999999999999999, 1.0, 1.0]\n [1.0, 0.9999999999999999, 1.0]\n [0.9999999999999998, 0.9999999999999999, 0.9999999999999998]\njulia> JudiLingMeasures.functional_load(F, Shat, cue_obj, cue_list=[\"#ab\", \"#bc\", \"#cd\"])\n3-element Vector{Any}:\n 1.0\n 0.9999999999999999\n 0.9999999999999998\njulia> JudiLingMeasures.functional_load(F, Shat, cue_obj, cue_list=[\"#ab\", \"#bc\", \"#cd\"], method=\"mse\")\n3-element Vector{Any}:\n  8.398316717482945\n  8.222104191091363\n 14.970231369151817\njulia> JudiLingMeasures.functional_load(F, Shat, cue_obj, method=\"mse\")\n3-element Vector{Any}:\n [8.398316717482945, 8.398316717482906, 8.398316717482906]\n [8.222104191091363, 8.222104191091224, 8.222104191091226]\n [14.970231369151817, 14.970231369151785, 14.970231369151788]\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.last_support-Tuple{JudiLing.Cue_Matrix_Struct, Union{SparseArrays.SparseMatrixCSC, Matrix}}","page":"Measures","title":"JudiLingMeasures.last_support","text":"last_support(cue_obj::JudiLing.Cue_Matrix_Struct,\n             Chat::Union{JudiLing.SparseMatrixCSC, Matrix})\n\nReturn the support in Chat for the last ngram of each target word.\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.lwlr-Tuple{Any, DataFrames.DataFrame}","page":"Measures","title":"JudiLingMeasures.lwlr","text":"lwlr(res_learn, pred_df::DataFrame)\n\nThe ratio between the predicted form's length and its weakest support from learn_paths.\n\nArguments\n\npred_df::DataFrame: The output of get_predicted_path_support\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.lwlr_chat-Tuple{Any, Any}","page":"Measures","title":"JudiLingMeasures.lwlr_chat","text":"lwlr_chat(res_learn, Chat)\n\nThe ratio between the predicted form's length and its weakest support in Chat.\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.mean_word_support-Tuple{Any, DataFrames.DataFrame}","page":"Measures","title":"JudiLingMeasures.mean_word_support","text":"mean_word_support(res_learn, pred_df::DataFrame)\n\nCompute the summed path support divided by each word form's length for each word in dat_val.\n\nArguments\n\nres_learn: The output of learn_paths\npred_df::DataFrame: The output of get_predicted_path_support\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.mean_word_support_chat-Tuple{Any, Any}","page":"Measures","title":"JudiLingMeasures.mean_word_support_chat","text":"mean_word_support_chat(res_learn, Chat)\n\nCompute the summed path support, taken from Chat, divided by each word form's length for each word in dat_val.\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.path_counts-Tuple{DataFrames.DataFrame}","page":"Measures","title":"JudiLingMeasures.path_counts","text":"path_counts(df::DataFrame)\n\nReturn the number of possible paths as returned by learn_paths.\n\nArguments\n\ndf::DataFrame: DataFrame of the output of learn_paths.\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.path_entropies_chat-Tuple{Any, Union{SparseArrays.SparseMatrixCSC, Matrix}}","page":"Measures","title":"JudiLingMeasures.path_entropies_chat","text":"path_entropies_chat(res_learn,\n                    Chat::Union{JudiLing.SparseMatrixCSC, Matrix})\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.path_entropies_scp-Tuple{DataFrames.DataFrame}","page":"Measures","title":"JudiLingMeasures.path_entropies_scp","text":"path_entropes_scp(df::DataFrame)\n\nComputes the entropy over the semantic supports for all candidates per target word form.\n\nArguments\n\ndf::DataFrame: DataFrame of the output of learn_paths.\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.path_sum-Tuple{DataFrames.DataFrame}","page":"Measures","title":"JudiLingMeasures.path_sum","text":"path_sum(pred_df::DataFrame)\n\nCompute the summed path support for each predicted word with highest support in dat_val.\n\nArguments\n\npred_df::DataFrame: The output of get_predicted_path_support\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.path_sum_chat-Tuple{Any, Union{SparseArrays.SparseMatrixCSC, Matrix}}","page":"Measures","title":"JudiLingMeasures.path_sum_chat","text":"path_sum_chat(res_learn,\n             Chat::Union{JudiLing.SparseMatrixCSC, Matrix})\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.rank-Tuple{Union{SparseArrays.SparseMatrixCSC, Matrix}}","page":"Measures","title":"JudiLingMeasures.rank","text":"rank(cor_s::Union{JudiLing.SparseMatrixCSC, Matrix})\n\nReturn the rank of the correct form among the comprehension candidates.\n\nArguments\n\ns_cor::Union{JudiLing.SparseMatrixCSC, Matrix}: the correlation matrix between S and Shat\n\nExamples\n\njulia> Shat = [[1 2 1 1]; [1 -2 3 1]; [1 -2 3 3]; [0 0 1 2]]\njulia> S = [[-1 2 1 1]; [1 2 3 1]; [1 2 0 1]; [0.5 -2 1.5 0]]\njulia> acc, cor_s = JudiLing.eval_SC(Shat, S, R=true)\njulia> rank(cor_s)\n4-element Vector{Any}:\n 2\n 2\n 4\n 1\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.recognition-Tuple{DataFrames.DataFrame}","page":"Measures","title":"JudiLingMeasures.recognition","text":"recognition(data::DataFrame)\n\nReturn a vector indicating whether a wordform was correctly understood. Not implemented.\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.semantic_support_for_form-Tuple{JudiLing.Cue_Matrix_Struct, Union{SparseArrays.SparseMatrixCSC, Matrix}}","page":"Measures","title":"JudiLingMeasures.semantic_support_for_form","text":"semantic_support_for_form(cue_obj::JudiLing.Cue_Matrix_Struct,\n             Chat::Union{JudiLing.SparseMatrixCSC, Matrix};\n             sum_supports::Bool=true)\n\nReturn the support in Chat for all target ngrams of each target word.\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.target_correlation-Tuple{Union{SparseArrays.SparseMatrixCSC, Matrix}, Union{SparseArrays.SparseMatrixCSC, Matrix}}","page":"Measures","title":"JudiLingMeasures.target_correlation","text":"target_correlation(cor_s::Union{JudiLing.SparseMatrixCSC, Matrix})\n\nCalculate the correlation between each predicted vector and its target vector.\n\nArguments\n\nXhat::Union{JudiLing.SparseMatrixCSC, Matrix}: matrix with predicted vectors in rows\nX::Union{JudiLing.SparseMatrixCSC, Matrix}: matrix with target vectors in rows\n\nExamples\n\njulia> Shat = [[1 2 1 1]; [1 -2 3 1]; [1 -2 3 3]; [0 0 1 2]]\njulia> S = [[-1 2 1 1]; [1 2 3 1]; [1 2 0 1]; [0.5 -2 1.5 0]]\njulia> target_correlation(Shat, S)\n4-element Vector{Float64}:\n  0.6622661785325219\n  0.2955402316445243\n -0.86386842558136\n  0.35478743759344955\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.target_correlation-Tuple{Union{SparseArrays.SparseMatrixCSC, Matrix}}","page":"Measures","title":"JudiLingMeasures.target_correlation","text":"target_correlation(cor_s::Union{JudiLing.SparseMatrixCSC, Matrix})\n\nCalculate the correlation between each predicted semantic vector and its target semantic vector.\n\nArguments\n\ns_cor::Union{JudiLing.SparseMatrixCSC, Matrix}: the correlation matrix between S and Shat\n\nExamples\n\njulia> Shat = [[1 2 1 1]; [1 -2 3 1]; [1 -2 3 3]; [0 0 1 2]]\njulia> S = [[-1 2 1 1]; [1 2 3 1]; [1 2 0 1]; [0.5 -2 1.5 0]]\njulia> acc, cor_s = JudiLing.eval_SC(Shat, S, R=true)\njulia> target_correlation(cor_s)\n4-element Vector{Float64}:\n  0.6622661785325219\n  0.2955402316445243\n -0.86386842558136\n  0.35478743759344955\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.target_path_sum-Tuple{Any}","page":"Measures","title":"JudiLingMeasures.target_path_sum","text":"target_path_sum(gpi)\n\nCompute the summed path support for each target word. Code by Yu-Ying Chuang.\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.total_distance-Tuple{JudiLing.Cue_Matrix_Struct, Union{SparseArrays.SparseMatrixCSC, Matrix}, Symbol}","page":"Measures","title":"JudiLingMeasures.total_distance","text":"total_distance(cue_obj::JudiLing.Cue_Matrix_Struct,\n               FG::Union{JudiLing.SparseMatrixCSC, Matrix},\n               mat_type::Symbol)\n\nCode by Yu-Ying Chuang.\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.uncertainty-Tuple{Union{SparseArrays.SparseMatrixCSC, Matrix}, Union{SparseArrays.SparseMatrixCSC, Matrix}, Union{SparseArrays.SparseMatrixCSC, Matrix}}","page":"Measures","title":"JudiLingMeasures.uncertainty","text":"function uncertainty(SC_val::Union{JudiLing.SparseMatrixCSC, Matrix},\n                     SChat_val::Union{JudiLing.SparseMatrixCSC, Matrix},\n                     SC_train::Union{JudiLing.SparseMatrixCSC, Matrix};\n                     method::Union{String, Symbol} = \"corr\")\n\nSum of correlation/mse/cosine similarity of SChatval with all vectors in SCval and S_train and the ranks of this correlation/mse/cosine similarity.\n\nMeasure developed by Motoki Saito. Note: the current version of uncertainty is not completely tested against its original implementation in pyldl.\n\nArguments\n\nSC::Union{JudiLing.SparseMatrixCSC, Matrix}: S or C matrix of the data of interest\nSChat::Union{JudiLing.SparseMatrixCSC, Matrix}: Shat or Chat matrix of the data of interest\nmethod::Union{String, Symbol} = \"corr\": Method to compute similarity\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.uncertainty-Tuple{Union{SparseArrays.SparseMatrixCSC, Matrix}, Union{SparseArrays.SparseMatrixCSC, Matrix}}","page":"Measures","title":"JudiLingMeasures.uncertainty","text":"function uncertainty(SC::Union{JudiLing.SparseMatrixCSC, Matrix},\n                     SChat::Union{JudiLing.SparseMatrixCSC, Matrix};\n                     method::Union{String, Symbol} = \"corr\")\n\nSum of correlation/mse/cosine similarity of SChat with all vectors in SC and the ranks of this correlation/mse/cosine similarity.\n\nMeasure developed by Motoki Saito. Note: the current version of uncertainty is not completely tested against its original implementation in pyldl.\n\nArguments\n\nSC::Union{JudiLing.SparseMatrixCSC, Matrix}: S or C matrix of the data of interest\nSChat::Union{JudiLing.SparseMatrixCSC, Matrix}: Shat or Chat matrix of the data of interest\nmethod::Union{String, Symbol} = \"corr\": Method to compute similarity\n\nExamples\n\njulia> Shat = [[1 2 1 1]; [1 -2 3 1]; [1 -2 3 3]; [0 0 1 2]]\njulia> S = [[-1 2 1 1]; [1 2 3 1]; [1 2 0 1]; [0.5 -2 1.5 0]]\njulia> JudiLingMeasures.uncertainty(S, Shat, method=\"corr\") # default\n4-element Vector{Float64}:\n 5.447907056192456\n 4.5888162633614\n 4.365247579557125\n 5.052415166794307\njulia> JudiLingMeasures.uncertainty(S, Shat, method=\"mse\")\n4-element Vector{Float64}:\n 3.5454545454545454\n 5.488372093023256\n 5.371428571428572\n 4.5\njulia> JudiLingMeasures.uncertainty(S, Shat, method=\"cosine\")\n4-element Vector{Float64}:\n 5.749202747845322\n 4.308224063773331\n 4.423630522948703\n 4.877528828745243\n\n\n\n\n\n","category":"method"},{"location":"measures.html#JudiLingMeasures.within_path_entropies-Tuple{DataFrames.DataFrame}","page":"Measures","title":"JudiLingMeasures.within_path_entropies","text":"within_path_entropies(pred_df::DataFrame)\n\nCompute the Shannon Entropy of the path supports for each word in dat_val.\n\nArguments\n\npred_df::DataFrame: The output of get_predicted_path_support\n\n\n\n\n\n","category":"method"},{"location":"index.html#JudiLingMeasures.jl","page":"Introduction","title":"JudiLingMeasures.jl","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"JudiLingMeasures enables easy calculation of measures in Discriminative Lexicon Models developed with JudiLing (Luo, Heitmeier, Chuang and Baayen, 2024).","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Most measures are based on R implementations in WpmWithLdl (Baayen et al., 2018) and LdlConvFunctions (Schmitz, 2021) and the python implementation in pyldl (Saito, 2022) (but all errors are my own). The conceptual work behind this package is therefore very much an effort of many people (see Bibliography). I have tried to acknowledge where each measure is used/introduced, but if I have missed anything, or you find any errors please let me know: maria dot heitmeier at uni dot tuebingen dot de.","category":"page"},{"location":"index.html#Installation","page":"Introduction","title":"Installation","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"using Pkg\nPkg.add(\"https://github.com/quantling/JudiLingMeasures.jl\")","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Requires JudiLing 0.5.5. Update your JudiLing version by running","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"using Pkg\nPkg.update(\"JudiLing\")","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"If this step does not work, i.e. the version of JudiLing is still not 0.5.5, refer to this forum post for a workaround.","category":"page"},{"location":"index.html#How-to-use","page":"Introduction","title":"How to use","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"For a demo of this package, please see notebooks/measures_demo.ipynb.","category":"page"},{"location":"index.html#Calculating-measures-in-this-package","page":"Introduction","title":"Calculating measures in this package","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"The following gives an overview over all measures available in this package. For a closer description of the parameters, please refer to Measures. All measures come with examples. In order to run them, first run the following piece of code, taken from the Readme of the JudiLing package. For a detailed explanation of this code please refer to the JudiLing Readme and documentation.","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"using JudiLing\nusing CSV # read csv files into dataframes\nusing DataFrames # parse data into dataframes\nusing JudiLingMeasures\n\n# if you haven't downloaded this file already, get it here:\ndownload(\"https://osf.io/2ejfu/download\", \"latin.csv\")\n\nlatin =\n    DataFrame(CSV.File(joinpath(@__DIR__, \"latin.csv\")));\n\ncue_obj = JudiLing.make_cue_matrix(\n    latin,\n    grams = 3,\n    target_col = :Word,\n    tokenized = false,\n    keep_sep = false\n);\n\nn_features = size(cue_obj.C, 2);\nS = JudiLing.make_S_matrix(\n    latin,\n    [\"Lexeme\"],\n    [\"Person\", \"Number\", \"Tense\", \"Voice\", \"Mood\"],\n    ncol = n_features\n);\n\nG = JudiLing.make_transform_matrix(S, cue_obj.C);\nF = JudiLing.make_transform_matrix(cue_obj.C, S);\n\nChat = S * G;\nShat = cue_obj.C * F;\n\nA = cue_obj.A;\nmax_t = JudiLing.cal_max_timestep(latin, :Word);","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Make sure that you set check_gold_path=true.","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"res_learn, gpi_learn, rpi_learn = JudiLing.learn_paths_rpi(\n    latin,\n    latin,\n    cue_obj.C,\n    S,\n    F,\n    Chat,\n    A,\n    cue_obj.i2f,\n    cue_obj.f2i, # api changed in 0.3.1\n    gold_ind = cue_obj.gold_ind,\n    Shat_val = Shat,\n    check_gold_path = true,\n    max_t = max_t,\n    max_can = 10,\n    grams = 3,\n    threshold = 0.05,\n    tokenized = false,\n    sep_token = \"_\",\n    keep_sep = false,\n    target_col = :Word,\n    issparse = :dense,\n    verbose = false,\n);","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Almost all available measures can be simply computed with","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"all_measures = JudiLingMeasures.compute_all_measures_train(latin, # the data of interest\n                                                     cue_obj, # the cue_obj of the training data\n                                                     Chat, # the Chat of the data of interest\n                                                     S, # the S matrix of the data of interest\n                                                     Shat, # the Shat matrix of the data of interest\n                                                     F, # the F matrix\n                                                     G, # the G matrix\n                                                     res_learn_train=res_learn, # the output of learn_paths for the data of interest\n                                                     gpi_learn_train=gpi_learn, # the gpi_learn object of the data of interest\n                                                     rpi_learn_train=rpi_learn); # the rpi_learn object of the data of interest","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"It's also possible to not compute measures based on the learn_paths algorithm:","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"all_measures = JudiLingMeasures.compute_all_measures_train(latin, # the data of interest\n                                                     cue_obj, # the cue_obj of the training data\n                                                     Chat, # the Chat of the training data\n                                                     S, # the S matrix of the training data\n                                                     Shat, # the Shat matrix of the training data\n                                                     F, # the F matrix\n                                                     G, # the G matrix); #","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"If low_cost_measures_only is set to true, only measures which are computationally relatively lean are computed.","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"The only measures not computed in JudiLingMeasures.compute_all_measures_train are those which return multiple values for each wordform. These are","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"\"Functional Load\"\n\"Semantic Support for Form\" with sum_supports=false","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"It is also possible to compute measures for validation data, please see the measures_demo.ipynb notebook for details.","category":"page"},{"location":"index.html#Overview-over-all-available-measures","page":"Introduction","title":"Overview over all available measures","text":"","category":"section"},{"location":"index.html#Measures-capturing-comprehension-(processing-on-the-semantic-side-of-the-network)","page":"Introduction","title":"Measures capturing comprehension (processing on the semantic side of the network)","text":"","category":"section"},{"location":"index.html#Measures-of-semantic-vector-length/uncertainty/activation","page":"Introduction","title":"Measures of semantic vector length/uncertainty/activation","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"L1Norm\nComputes the L1-Norm (city-block distance) of the predicted semantic vectors hatS:\nExample:\nJudiLingMeasures.L1Norm(Shat)\nUsed in Schmitz et al. (2021), Stein and Plag (2021) (called Semantic Vector length in their paper), Saito (2022) (called VecLen)\nL2Norm\nComputes the L2-Norm (euclidean distance) of the predicted semantic vectors hatS:\nExample:\nJudiLingMeasures.L2Norm(Shat)\nUsed in Schmitz et al. (2021)","category":"page"},{"location":"index.html#Measures-of-semantic-neighbourhood","page":"Introduction","title":"Measures of semantic neighbourhood","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Density\nComputes the average correlation/cosine similarity of each predicted semantic vector in hatS with the n most correlated/closest semantic vectors in S:\nExample:\n_, cor_s = JudiLing.eval_SC(Shat, S, R=true)\ncorrelation_density = JudiLingMeasures.density(cor_s, 10)\n\ncosine_sims = JudiLingMeasures.cosine_similarity(Shat, S)\ncosine_density = JudiLingMeasures.density(cosine_sim, 10)\nUsed in Heitmeier et al. (2022) (called Semantic Density, based on Cosine Similarity), Schmitz et al. (2021), Stein and Plag (2021) (called Semantic Density, based on correlation)\nALC\nAverage Lexical Correlation. Computes the average correlation between each predicted semantic vector and all semantic vectors in S.\nExample:\n_, cor_s = JudiLing.eval_SC(Shat, S, R=true)\nJudiLingMeasures.ALC(cor_s)\nUsed in Schmitz et al. (2021), Chuang et al. (2020)\nEDNN\nEuclidean Distance Nearest Neighbour. Computes the euclidean distance between each predicted semantic vector and all semantic vectors in S and returns for each predicted semantic vector the distance to the closest neighbour.\nExample:\nJudiLingMeasures.EDNN(Shat, S)\nUsed in Schmitz et al. (2021), Chuang et al. (2020)\nNNC\nNearest Neighbour Correlation. Computes the correlation between each predicted semantic vector and all semantic vectors in S and returns for each predicted semantic vector the correlation to the closest neighbour.\nExample:\n_, cor_s = JudiLing.eval_SC(Shat, S, R=true)\nJudiLingMeasures.NNC(cor_s)\nUsed in Schmitz et al. (2021), Chuang et al. (2020)\nTotal Distance (F)\nSummed Euclidean distances between predicted semantic vectors of trigrams in the target form. Code by Yu-Ying Chuang.\nExample:\nJudiLingMeasures.total_distance(cue_obj, F, :F)\nUsed in Chuang et al. (to appear)","category":"page"},{"location":"index.html#Measures-of-comprehension-accuracy/uncertainty","page":"Introduction","title":"Measures of comprehension accuracy/uncertainty","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"TargetCorrelation\nCorrelation between each predicted semantic vector and its target semantic vector in S.\nExample:\n_, cor_s = JudiLing.eval_SC(Shat, S, R=true)\nJudiLingMeasures.TargetCorrelation(cor_s)\nUsed in Stein and Plag (2021) and Saito (2022) (but called PredAcc there)\nRank\nRank of the correlation with the target semantics among the correlations between the predicted semantic vector and all semantic vectors in S.\nExample:\n_, cor_s = JudiLing.eval_SC(Shat, S, R=true)\nJudiLingMeasures.rank(cor_s)\nRecognition\nWhether a word form was correctly comprehended. Not currently implemented.\nNOT YET IMPLEMENTED\nComprehension Uncertainty\nSum of production of correlation/mse/cosine cosimilarity of shat with all vectors in S and the ranks of this correlation/mse/cosine similarity.\nNote: the current version of Comprehension Uncertainty is not completely tested against its original implementation in pyldl.\nExample:\nJudiLingMeasures.uncertainty(S, Shat, method=\"corr\") # default\nJudiLingMeasures.uncertainty(S, Shat, method=\"mse\")\nJudiLingMeasures.uncertainty(S, Shat, method=\"cosine\")\nUsed in Saito (2022).\nFunctional Load\nCorrelation/MSE of rows in F of triphones in word w and the target semantic vector of w.\nNote: the current version of Functional Load is not completely tested against its original implementation in pyldl.\nExample:\nJudiLingMeasures.functional_load(F, Shat, cue_obj, method=\"corr\")\nJudiLingMeasures.functional_load(F, Shat, cue_obj, method=\"mse\")\nInstead of returning the functional load for each cue in each word, a list of cues can also be specified. In this case it is assumed that cues are specified in the same order as the words they are to be compared to are specified in F and Shat.\nJudiLingMeasures.functional_load(F[:,1:6], Shat[1:6,:], cue_obj, cue_list = [\"#vo\", \"#vo\", \"#vo\",\"#vo\",\"#vo\",\"#vo\"])\nJudiLingMeasures.functional_load(F[:,1:6], Shat[1:6,:], cue_obj, cue_list = [\"#vo\", \"#vo\", \"#vo\",\"#vo\",\"#vo\",\"#vo\"], method=\"mse\")\nUsed in Saito (2022).","category":"page"},{"location":"index.html#Measures-capturing-production-(processing-on-the-form-side-of-the-network)","page":"Introduction","title":"Measures capturing production (processing on the form side of the network)","text":"","category":"section"},{"location":"index.html#Measures-of-production-accuracy/support/uncertainty-for-the-predicted-form","page":"Introduction","title":"Measures of production accuracy/support/uncertainty for the predicted form","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"SCPP\nThe correlation between the predicted semantics of the word form produced by the path algorithm and the target semantics.\nExample:\ndf = JudiLingMeasures.get_res_learn_df(res_learn, latin, cue_obj, cue_obj)\nJudiLingMeasures.SCPP(df, latin)\nUsed in Chuang et al. (2020) (based on WpmWithLDL)\nPathSum\nThe summed path supports for the highest supported predicted form, produced by the path algorithm. Path supports are taken from the hatY matrices.\nExample:\npred_df = JudiLing.write2df(rpi_learn)\nJudiLingMeasures.path_sum(pred_df)\nUsed in Schmitz et al. (2021) (but based on WpmWithLDL)\nTargetPathSum\nThe summed path supports for the target word form, produced by the path algorithm. Path supports are taken from the hatY matrices.\nExample:\nJudiLingMeasures.target_path_sum(gpi_learn)\nUsed in Chuang et al. (2022) (but called Triphone Support)\nPathSumChat\nThe summed path supports for the highest supported predicted form, produced by the path algorithm. Path supports are taken from the hatC matrix.\nExample:\nJudiLingMeasures.path_sum_chat(res_learn, Chat)\nC-Precision\nCorrelation between the predicted form vector and the target form vector.\nExample:\nJudiLingMeasures.c_precision(Chat, cue_obj.C)\nUsed in Heitmeier et al. (2022), Gahl and Baayen (2022) (called Semantics to Form Mapping Precision)\nL1Chat\nL1-Norm of the predicted hatc vectors.\nExample:\nJudiLingMeasures.L1Norm(Chat)\nUsed in Heitmeier et al. (2022)\nSemantic Support for Form\nSum of activation of ngrams in the target wordform.\nExample:\nJudiLingMeasures.semantic_support_for_form(cue_obj, Chat)\nInstead of summing the activations, the function can also return the activation for each ngram:\nJudiLingMeasures.semantic_support_for_form(cue_obj, Chat, sum_supports=false)\nUsed in Gahl and Baayen (2022) (unclear which package this was based on?) The activation of individual ngrams was used in Saito (2022).","category":"page"},{"location":"index.html#Measures-of-production-accuracy/support/uncertainty-for-the-target-form","page":"Introduction","title":"Measures of production accuracy/support/uncertainty for the target form","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Production Uncertainty\nSum of production of correlation/mse/cosine similarity of chat with all vectors in C and the ranks of this correlation/mse/cosine similarity.\nNote: the current version of Production Uncertainty is not completely tested against its original implementation in pyldl.\nExample:\nJudiLingMeasures.uncertainty(cue_obj.C, Chat, method=\"corr\") # default\nJudiLingMeasures.uncertainty(cue_obj.C, Chat, method=\"mse\")\nJudiLingMeasures.uncertainty(cue_obj.C, Chat, method=\"cosine\")\nUsed in Saito (2022)\nTotal Distance (G)\nSummed Euclidean distances between predicted form vectors of trigrams in the target form. Code by Yu-Ying Chuang.\nExample:\nJudiLingMeasures.total_distance(cue_obj, G, :G)\nUsed in Chuang et al. (to appear)","category":"page"},{"location":"index.html#Measures-of-support-for-the-predicted-path,-focusing-on-the-path-transitions-and-components-of-the-path","page":"Introduction","title":"Measures of support for the predicted path, focusing on the path transitions and components of the path","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"LastSupport\nThe support for the last trigram of each target word in the Chat matrix.\nExample:\nJudiLingMeasures.last_support(cue_obj, Chat)\nUsed in Schmitz et al. (2021) (called Support in their paper).\nWithinPathEntropies\nThe entropy over path supports for the highest supported predicted form, produced by the path algorithm. Path supports are taken from the hatY matrices.\nExample:\npred_df = JudiLing.write2df(rpi_learn)\nJudiLingMeasures.within_path_entropies(pred_df)\nMeanWordSupport\nSummed path support divided by each word form's length. Path supports are taken from the hatY matrices.\nExample:\npred_df = JudiLing.write2df(rpi_learn)\nJudiLingMeasures.mean_word_support(res_learn, pred_df)\nMeanWordSupportChat\nSummed path support divided by each word form's length. Path supports are taken from the hatC matrix.\nExample:\nJudiLingMeasures.mean_word_support_chat(res_learn, Chat)\nUsed in Stein and Plag (2021) (but based on WpmWithLDL)\nlwlr\nThe ratio between the predicted form's length and its weakest support from the production algorithm. Supports taken from the hatY matrices.\nExample:\npred_df = JudiLing.write2df(rpi_learn)\nJudiLingMeasures.lwlr(res_learn, pred_df)\nlwlrChat\nThe ratio between the predicted form's length and its weakest support. Supports taken from the hatC matrix.\nExample:\nJudiLingMeasures.lwlr_chat(res_learn, Chat)","category":"page"},{"location":"index.html#Measures-of-support-for-competing-forms","page":"Introduction","title":"Measures of support for competing forms","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"PathCounts\nThe number of candidates predicted by the path algorithm.\nExample:\ndf = JudiLingMeasures.get_res_learn_df(res_learn, latin, cue_obj, cue_obj)\nJudiLingMeasures.PathCounts(df)\nUsed in Schmitz et al. (2021) (but based on WpmWithLDL)\nPathEntropiesChat\nThe entropy over the summed path supports for the candidate forms produced by the path algorithm. Path supports are taken from the hatC matrix.\nExample:\nJudiLingMeasures.path_entropies_chat(res_learn, Chat)\nUsed in Schmitz et al. (2021) (but based on WpmWithLDL), Stein and Plag (2021) (but based on WpmWithLDL)\nPathEntropiesSCP\nThe entropy over the semantic supports for the candidate forms produced by the path algorithm.\nExample:\ndf = JudiLingMeasures.get_res_learn_df(res_learn, latin, cue_obj, cue_obj)\nJudiLingMeasures.path_entropies_scp(df)\nALDC\nAverage Levenstein Distance of Candidates. Average of Levenshtein distance between each predicted word form candidate and the target word form.\nExample:\ndf = JudiLingMeasures.get_res_learn_df(res_learn, latin, cue_obj, cue_obj)\nJudiLingMeasures.ALDC(df)\nUsed in Schmitz et al. (2021), Chuang et al. (2020) (both based on WpmWithLDL)","category":"page"},{"location":"index.html#Bibliography","page":"Introduction","title":"Bibliography","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Baayen, R. H., Chuang, Y.-Y., and Blevins, J. P. (2018). Inflectional morphology with linear mappings. The Mental Lexicon, 13 (2), 232-270.","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Chuang, Y.-Y., Kang, M., Luo, X. F. and Baayen, R. H. (to appear). Vector Space Morphology with Linear Discriminative Learning. In Crepaldi, D. (Ed.) Linguistic morphology in the mind and brain.","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Chuang, Y-Y., Vollmer, M-l., Shafaei-Bajestan, E., Gahl, S., Hendrix, P., and Baayen, R. H. (2020). The processing of pseudoword form and meaning in production and comprehension: A computational modeling approach using Linear Discriminative Learning. Behavior Research Methods, 1-51.","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Gahl, S., and Baayen, R. H. (2022). Time and thyme again: Connecting spoken word duration to models of the mental lexicon. OSF, January 22, 1-41.","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Heitmeier, M., Chuang, Y.-Y., and Baayen, R. H. (2022). How trial-to-trial learning shapes mappings in the mental lexicon: Modelling Lexical Decision with Linear Discriminative Learning. ArXiv, July 1, 1-38.","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Saito, Motoki (2022): pyldl - Linear Discriminative Learning in Python. URL: https://github.com/msaito8623/pyldl","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Schmitz, Dominic. (2021). LDLConvFunctions: Functions for measure computation, extraction, and other handy stuff. R package version 1.2.0.1. URL: https://github.com/dosc91/LDLConvFunctions","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Schmitz, D., Plag, I., Baer-Henney, D., & Stein, S. D. (2021). Durational differences of word-final/s/emerge from the lexicon: Modelling morpho-phonetic effects in pseudowords with linear discriminative learning. Frontiers in psychology, 12.","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Stein, S. D., & Plag, I. (2021). Morpho-phonetic effects in speech production: Modeling the acoustic duration of English derived words with linear discriminative learning. Frontiers in Psychology, 12.","category":"page"},{"location":"helpers.html","page":"Helper Functions","title":"Helper Functions","text":"CurrentModule = JudiLingMeasures","category":"page"},{"location":"helpers.html","page":"Helper Functions","title":"Helper Functions","text":"Pages = [\"helpers.md\"]","category":"page"},{"location":"helpers.html#Helpers","page":"Helper Functions","title":"Helpers","text":"","category":"section"},{"location":"helpers.html","page":"Helper Functions","title":"Helper Functions","text":"This page contains information on additional helper functions in this package.","category":"page"},{"location":"helpers.html","page":"Helper Functions","title":"Helper Functions","text":"Modules = [JudiLingMeasures]\nPages   = [\"helpers.jl\"]\nOrder = [:module, :type, :function, :macro]","category":"page"},{"location":"helpers.html#JudiLingMeasures.compute_all_measures_train-Tuple{DataFrames.DataFrame, JudiLing.Cue_Matrix_Struct, Union{SparseArrays.SparseMatrixCSC, Matrix}, Union{SparseArrays.SparseMatrixCSC, Matrix}, Union{SparseArrays.SparseMatrixCSC, Matrix}, Union{Missing, SparseArrays.SparseMatrixCSC, Matrix}, Union{Missing, SparseArrays.SparseMatrixCSC, Matrix}}","page":"Helper Functions","title":"JudiLingMeasures.compute_all_measures_train","text":"function compute_all_measures_train(data_train::DataFrame,\n                                    cue_obj_train::JudiLing.Cue_Matrix_Struct,\n                                    Chat_train::Union{JudiLing.SparseMatrixCSC, Matrix},\n                                    S_train::Union{JudiLing.SparseMatrixCSC, Matrix},\n                                    Shat_train::Union{JudiLing.SparseMatrixCSC, Matrix},\n                                    F_train::Union{JudiLing.SparseMatrixCSC, Matrix},\n                                    G_train::Union{JudiLing.SparseMatrixCSC, Matrix};\n                                    res_learn_train::Union{Array{Array{JudiLing.Result_Path_Info_Struct,1},1}, Missing}=missing,\n                                    gpi_learn_train::Union{Array{JudiLing.Gold_Path_Info_Struct,1}, Missing}=missing,\n                                    rpi_learn_train::Union{Array{JudiLing.Gold_Path_Info_Struct,1}, Missing}=missing,\n                                    sem_density_n::Int64=8,\n                                    calculate_production_uncertainty::Bool=false,\n                                    low_cost_measures_only::Bool=false)\n\nCompute all measures currently available in JudiLingMeasures for the training data.\n\nArguments\n\ndata_train::DataFrame: The data for which measures should be calculated (the training data).\ncue_obj_train::JudiLing.Cue_Matrix_Struct: The cue object of the training data.\nChat_train::Union{JudiLing.SparseMatrixCSC, Matrix}: The Chat matrix of the training data.\nS_train::Union{JudiLing.SparseMatrixCSC, Matrix}: The S matrix of the training data.\nShat_train::Union{JudiLing.SparseMatrixCSC, Matrix}: The Shat matrix of the training data.\nF_train::Union{JudiLing.SparseMatrixCSC, Matrix}: Comprehension mapping matrix for the training data.\nG_train::Union{JudiLing.SparseMatrixCSC, Matrix}: Production mapping matrix for the training data.\nres_learn_train::Union{Array{Array{JudiLing.Result_Path_Info_Struct,1},1}, Missing}=missing: The first output of JudiLing.learnpathsrpi (with check_gold_path=true)\ngpi_learn_train::Union{Array{JudiLing.Gold_Path_Info_Struct,1}, Missing}=missing: The second output of JudiLing.learnpathsrpi (with check_gold_path=true)\nrpi_learn_train::Union{Array{JudiLing.Gold_Path_Info_Struct,1}, Missing}=missing: The third output of JudiLing.learnpathsrpi (with check_gold_path=true)\nsem_density_n::Int64=8: Number of neighbours to take into account in Semantic Density measure.\ncalculate_production_uncertainty: \"Production Uncertainty\" is computationally very heavy for large C matrices, therefore its computation is turned off by default.\nlow_cost_measures_only::Bool=false: Only compute measures which are not computationally heavy. Recommended for very large datasets.\n\nReturns\n\nresults::DataFrame: A dataframe with all information in data_train plus all the computed measures.\n\n\n\n\n\n","category":"method"},{"location":"helpers.html#JudiLingMeasures.compute_all_measures_train-Tuple{DataFrames.DataFrame, JudiLing.Cue_Matrix_Struct, Union{SparseArrays.SparseMatrixCSC, Matrix}, Union{SparseArrays.SparseMatrixCSC, Matrix}, Union{SparseArrays.SparseMatrixCSC, Matrix}}","page":"Helper Functions","title":"JudiLingMeasures.compute_all_measures_train","text":"function compute_all_measures_train(data_train::DataFrame,\n                                    cue_obj_train::JudiLing.Cue_Matrix_Struct,\n                                    Chat_train::Union{JudiLing.SparseMatrixCSC, Matrix},\n                                    S_train::Union{JudiLing.SparseMatrixCSC, Matrix},\n                                    Shat_train::Union{JudiLing.SparseMatrixCSC, Matrix};\n                                    res_learn_train::Union{Array{Array{JudiLing.Result_Path_Info_Struct,1},1}, Missing}=missing,\n                                    gpi_learn_train::Union{Array{JudiLing.Gold_Path_Info_Struct,1}, Missing}=missing,\n                                    rpi_learn_train::Union{Array{JudiLing.Gold_Path_Info_Struct,1}, Missing}=missing,\n                                    sem_density_n::Int64=8,\n                                    calculate_production_uncertainty::Bool=false,\n                                    low_cost_measures_only::Bool=false)\n\nCompute all measures currently available in JudiLingMeasures for the training data if F and G are not available (usually for DDL models).\n\nArguments\n\ndata_train::DataFrame: The data for which measures should be calculated (the training data).\ncue_obj_train::JudiLing.Cue_Matrix_Struct: The cue object of the training data.\nChat_train::Union{JudiLing.SparseMatrixCSC, Matrix}: The Chat matrix of the training data.\nS_train::Union{JudiLing.SparseMatrixCSC, Matrix}: The S matrix of the training data.\nShat_train::Union{JudiLing.SparseMatrixCSC, Matrix}: The Shat matrix of the training data.\nres_learn_train::Union{Array{Array{JudiLing.Result_Path_Info_Struct,1},1}, Missing}=missing: The first output of JudiLing.learnpathsrpi (with check_gold_path=true)\ngpi_learn_train::Union{Array{JudiLing.Gold_Path_Info_Struct,1}, Missing}=missing: The second output of JudiLing.learnpathsrpi (with check_gold_path=true)\nrpi_learn_train::Union{Array{JudiLing.Gold_Path_Info_Struct,1}, Missing}=missing: The third output of JudiLing.learnpathsrpi (with check_gold_path=true)\nsem_density_n::Int64=8: Number of neighbours to take into account in Semantic Density measure.\ncalculate_production_uncertainty: \"Production Uncertainty\" is computationally very heavy for large C matrices, therefore its computation is turned off by default.\nlow_cost_measures_only::Bool=false: Only compute measures which are not computationally heavy. Recommended for very large datasets.\n\nReturns\n\nresults::DataFrame: A dataframe with all information in data_train plus all the computed measures.\n\n\n\n\n\n","category":"method"},{"location":"helpers.html#JudiLingMeasures.compute_all_measures_val-Tuple{DataFrames.DataFrame, JudiLing.Cue_Matrix_Struct, JudiLing.Cue_Matrix_Struct, Union{SparseArrays.SparseMatrixCSC, Matrix}, Union{SparseArrays.SparseMatrixCSC, Matrix}, Union{SparseArrays.SparseMatrixCSC, Matrix}, Union{SparseArrays.SparseMatrixCSC, Matrix}, Union{Missing, SparseArrays.SparseMatrixCSC, Matrix}, Union{Missing, SparseArrays.SparseMatrixCSC, Matrix}}","page":"Helper Functions","title":"JudiLingMeasures.compute_all_measures_val","text":"function compute_all_measures_val(data_val::DataFrame,\n                                  cue_obj_train::JudiLing.Cue_Matrix_Struct,\n                                  cue_obj_val::JudiLing.Cue_Matrix_Struct,\n                                  Chat_val::Union{JudiLing.SparseMatrixCSC, Matrix},\n                                  S_train::Union{JudiLing.SparseMatrixCSC, Matrix},\n                                  S_val::Union{JudiLing.SparseMatrixCSC, Matrix},\n                                  Shat_val::Union{JudiLing.SparseMatrixCSC, Matrix},\n                                  F_train::Union{JudiLing.SparseMatrixCSC, Matrix},\n                                  G_train::Union{JudiLing.SparseMatrixCSC, Matrix};\n                                  res_learn_val::Union{Array{Array{JudiLing.Result_Path_Info_Struct,1},1}, Missing}=missing,\n                                  gpi_learn_val::Union{Array{JudiLing.Gold_Path_Info_Struct,1}, Missing}=missing,\n                                  rpi_learn_val::Union{Array{JudiLing.Gold_Path_Info_Struct,1}, Missing}=missing,\n                                  sem_density_n::Int64=8,\n                                  calculate_production_uncertainty::Bool=false,\n                                  low_cost_measures_only::Bool=false)\n\nCompute all measures currently available in JudiLingMeasures for the validation data.\n\nArguments\n\ndata_val::DataFrame: The data for which measures should be calculated (the validation data).\ncue_obj_train::JudiLing.Cue_Matrix_Struct: The cue object of the training data.\ncue_obj_val::JudiLing.Cue_Matrix_Struct: The cue object of the validation data.\nChat_val::Union{JudiLing.SparseMatrixCSC, Matrix}: The Chat matrix of the validation data.\nS_train::Union{JudiLing.SparseMatrixCSC, Matrix}: The S matrix of the training data.\nS_val::Union{JudiLing.SparseMatrixCSC, Matrix}: The S matrix of the validation data.\nShat_val::Union{JudiLing.SparseMatrixCSC, Matrix}: The Shat matrix of the data of interest.\nF_train::Union{JudiLing.SparseMatrixCSC, Matrix}: Comprehension mapping matrix for the training data.\nG_train::Union{JudiLing.SparseMatrixCSC, Matrix}: Production mapping matrix for the training data.\nres_learn_val::Union{Array{Array{JudiLing.Result_Path_Info_Struct,1},1}, Missing}=missing: The first output of JudiLing.learnpathsrpi (with check_gold_path=true)\ngpi_learn_val::Union{Array{JudiLing.Gold_Path_Info_Struct,1}, Missing}=missing: The second output of JudiLing.learnpathsrpi (with check_gold_path=true)\nrpi_learn_val::Union{Array{JudiLing.Gold_Path_Info_Struct,1}, Missing}=missing: The third output of JudiLing.learnpathsrpi (with check_gold_path=true)\nlow_cost_measures_only::Bool=false: Only compute measures which are not computationally heavy. Recommended for very large datasets.\n\nReturns\n\nresults::DataFrame: A dataframe with all information in data_val plus all the computed measures.\n\n\n\n\n\n","category":"method"},{"location":"helpers.html#JudiLingMeasures.compute_all_measures_val-Tuple{DataFrames.DataFrame, JudiLing.Cue_Matrix_Struct, JudiLing.Cue_Matrix_Struct, Vararg{Union{SparseArrays.SparseMatrixCSC, Matrix}, 4}}","page":"Helper Functions","title":"JudiLingMeasures.compute_all_measures_val","text":"function compute_all_measures_val(data_val::DataFrame,\n                                  cue_obj_train::JudiLing.Cue_Matrix_Struct,\n                                  cue_obj_val::JudiLing.Cue_Matrix_Struct,\n                                  Chat_val::Union{JudiLing.SparseMatrixCSC, Matrix},\n                                  S_train::Union{JudiLing.SparseMatrixCSC, Matrix},\n                                  S_val::Union{JudiLing.SparseMatrixCSC, Matrix},\n                                  Shat_val::Union{JudiLing.SparseMatrixCSC, Matrix};\n                                  res_learn_val::Union{Array{Array{JudiLing.Result_Path_Info_Struct,1},1}, Missing}=missing,\n                                  gpi_learn_val::Union{Array{JudiLing.Gold_Path_Info_Struct,1}, Missing}=missing,\n                                  rpi_learn_val::Union{Array{JudiLing.Gold_Path_Info_Struct,1}, Missing}=missing,\n                                  sem_density_n::Int64=8,\n                                  calculate_production_uncertainty::Bool=false,\n                                  low_cost_measures_only::Bool=false)\n\nCompute all measures currently available in JudiLingMeasures for the validation data if F and G are not available (usually for DDL models).\n\nArguments\n\ndata_val::DataFrame: The data for which measures should be calculated (the validation data).\ncue_obj_train::JudiLing.Cue_Matrix_Struct: The cue object of the training data.\ncue_obj_val::JudiLing.Cue_Matrix_Struct: The cue object of the validation data.\nChat_val::Union{JudiLing.SparseMatrixCSC, Matrix}: The Chat matrix of the validation data.\nS_train::Union{JudiLing.SparseMatrixCSC, Matrix}: The S matrix of the training data.\nS_val::Union{JudiLing.SparseMatrixCSC, Matrix}: The S matrix of the validation data.\nShat_val::Union{JudiLing.SparseMatrixCSC, Matrix}: The Shat matrix of the data of interest.\nres_learn_val::Union{Array{Array{JudiLing.Result_Path_Info_Struct,1},1}, Missing}=missing: The first output of JudiLing.learnpathsrpi (with check_gold_path=true)\ngpi_learn_val::Union{Array{JudiLing.Gold_Path_Info_Struct,1}, Missing}=missing: The second output of JudiLing.learnpathsrpi (with check_gold_path=true)\nrpi_learn_val::Union{Array{JudiLing.Gold_Path_Info_Struct,1}, Missing}=missing: The third output of JudiLing.learnpathsrpi (with check_gold_path=true)\nlow_cost_measures_only::Bool=false: Only compute measures which are not computationally heavy. Recommended for very large datasets.\n\nReturns\n\nresults::DataFrame: A dataframe with all information in data_val plus all the computed measures.\n\n\n\n\n\n","category":"method"},{"location":"helpers.html#JudiLingMeasures.correlation_diagonal_rowwise-Tuple{Any, Any}","page":"Helper Functions","title":"JudiLingMeasures.correlation_diagonal_rowwise","text":"function correlation_diagonal_rowwise(S1, S2)\n\nComputes the pairwise correlation of each row in S1 and S2, i.e. only the diagonal of the correlation matrix.\n\nExample\n\njulia> ma1 = [[1 2 3]; [-1 -2 -3]; [1 2 3]]\njulia> ma4 = [[1 2 2]; [1 -2 -3]; [0 2 3]]\njulia> correlation_diagonal_rowwise(ma1, ma4)\n3-element Array{Float64,1}:\n 0.8660254037844387\n 0.9607689228305228\n 0.9819805060619657\n\n\n\n\n\n","category":"method"},{"location":"helpers.html#JudiLingMeasures.correlation_rowwise-Tuple{Union{SparseArrays.SparseMatrixCSC, Matrix}, Union{SparseArrays.SparseMatrixCSC, Matrix}}","page":"Helper Functions","title":"JudiLingMeasures.correlation_rowwise","text":"correlation_rowwise(S1::Union{JudiLing.SparseMatrixCSC, Matrix},\n                    S2::Union{JudiLing.SparseMatrixCSC, Matrix})\n\nCompute the correlation between each row of S1 with all rows in S2.\n\nExample\n\njulia> ma2 = [[1 2 1 1]; [1 -2 3 1]; [1 -2 3 3]; [0 0 1 2]]\njulia> ma3 = [[-1 2 1 1]; [1 2 3 1]; [1 2 0 1]; [0.5 -2 1.5 0]]\njulia> correlation_rowwise(ma2, ma3)\n4×4 Matrix{Float64}:\n  0.662266   0.174078    0.816497  -0.905822\n -0.41762    0.29554    -0.990148   0.988623\n -0.308304   0.0368355  -0.863868   0.862538\n  0.207514  -0.0909091  -0.426401   0.354787\n\n\n\n\n\n","category":"method"},{"location":"helpers.html#JudiLingMeasures.cosine_similarity-Tuple{Any, Any}","page":"Helper Functions","title":"JudiLingMeasures.cosine_similarity","text":"cosine_similarity(s_hat_collection, S)\n\nCalculate cosine similarity between all predicted and all target semantic vectors\n\nExample\n\njulia> ma1 = [[1 2 3]; [-1 -2 -3]; [1 2 3]]\njulia> ma4 = [[1 2 2]; [1 -2 -3]; [0 2 3]]\njulia> cosine_similarity(ma1, ma4)\n3×3 Array{Float64,2}:\n  0.979958  -0.857143   0.963624\n -0.979958   0.857143  -0.963624\n  0.979958  -0.857143   0.963624\n\n\n\n\n\n","category":"method"},{"location":"helpers.html#JudiLingMeasures.count_rows-Tuple{Any}","page":"Helper Functions","title":"JudiLingMeasures.count_rows","text":"count_rows(dat::DataFrame)\n\nGet the number of rows in dat.\n\nExamples\n\njulia> dat = DataFrame(\"text\"=>[1,2,3])\njulia> count_rows(dat)\n 3\n\n\n\n\n\n","category":"method"},{"location":"helpers.html#JudiLingMeasures.entropy-Tuple{Union{Missing, SubArray, Array}}","page":"Helper Functions","title":"JudiLingMeasures.entropy","text":"entropy(ps::Union{Missing, Array, SubArray})\n\nCompute the Shannon-Entropy of the values in ps bigger than 0.\n\nNote: the result of this is entropy function is different to other entropy measures as a) the values are scaled between 0 and 1 first, and b) log2 instead of log is used\n\nExamples\n\njulia> ps = [0.1, 0.2, 0.9]\njulia> entropy(ps)\n1.0408520829727552\n\n\n\n\n\n","category":"method"},{"location":"helpers.html#JudiLingMeasures.euclidean_distance_rowwise-Tuple{Union{SparseArrays.SparseMatrixCSC, Matrix}, Union{SparseArrays.SparseMatrixCSC, Matrix}}","page":"Helper Functions","title":"JudiLingMeasures.euclidean_distance_rowwise","text":"euclidean_distance_rowwise(Shat::Union{JudiLing.SparseMatrixCSC, Matrix},\n                         S::Union{JudiLing.SparseMatrixCSC, Matrix})\n\nCalculate the pairwise Euclidean distances between all rows in Shat and S.\n\nThrows error if missing is included in any of the arrays.\n\nExamples\n\njulia> ma1 = [[1 2 3]; [-1 -2 -3]; [1 2 3]]\njulia> ma4 = [[1 2 2]; [1 -2 -3]; [0 2 3]]\njulia> euclidean_distance_rowwise(ma1, ma4)\n3×3 Matrix{Float64}:\n 1.0     7.2111  1.0\n 6.7082  2.0     7.28011\n 1.0     7.2111  1.0\n\n\n\n\n\n","category":"method"},{"location":"helpers.html#JudiLingMeasures.get_avg_levenshtein-Tuple{Union{SubArray, Array}, Union{SubArray, Array}}","page":"Helper Functions","title":"JudiLingMeasures.get_avg_levenshtein","text":"get_avg_levenshtein(targets::Array, preds::Array)\n\nGet the average levenshtein distance between two lists of strings.\n\nExamples\n\njulia> targets = [\"abc\", \"abc\", \"abc\"]\njulia> preds = [\"abd\", \"abc\", \"ebd\"]\njulia> get_avg_levenshtein(targets, preds)\n 1.0\n\n\n\n\n\n","category":"method"},{"location":"helpers.html#JudiLingMeasures.get_nearest_neighbour_eucl-Tuple{Matrix}","page":"Helper Functions","title":"JudiLingMeasures.get_nearest_neighbour_eucl","text":"get_nearest_neighbour_eucl(eucl_sims::Matrix)\n\nGet the nearest neighbour for each row in eucl_sims.\n\nExamples\n\njulia> ma1 = [[1 2 3]; [-1 -2 -3]; [1 2 3]]\njulia> ma4 = [[1 2 2]; [1 -2 -3]; [0 2 3]]\njulia> eucl_sims = euclidean_distance_array(ma1, ma4)\njulia> get_nearest_neighbour_eucl(eucl_sims)\n3-element Vector{Float64}:\n 1.0\n 2.0\n 1.0\n\n\n\n\n\n","category":"method"},{"location":"helpers.html#JudiLingMeasures.get_res_learn_df-NTuple{4, Any}","page":"Helper Functions","title":"JudiLingMeasures.get_res_learn_df","text":"get_res_learn_df(res_learn_val, data_val, cue_obj_train, cue_obj_val)\n\nWrapper for JudiLing.write2df for easier use.\n\n\n\n\n\n","category":"method"},{"location":"helpers.html#JudiLingMeasures.l1_rowwise-Tuple{Union{SparseArrays.SparseMatrixCSC, Matrix}}","page":"Helper Functions","title":"JudiLingMeasures.l1_rowwise","text":"l1_rowwise(M::Union{JudiLing.SparseMatrixCSC, Matrix})\n\nCompute the L1 Norm of each row of M.\n\nExample\n\njulia> ma1 = [[1 2 3]; [-1 -2 -3]; [1 2 3]]\njulia> l1_rowwise(ma1)\n3×1 Matrix{Int64}:\n 6\n 6\n 6\n\n\n\n\n\n","category":"method"},{"location":"helpers.html#JudiLingMeasures.l2_rowwise-Tuple{Union{SparseArrays.SparseMatrixCSC, Matrix}}","page":"Helper Functions","title":"JudiLingMeasures.l2_rowwise","text":"l2_rowwise(M::Union{JudiLing.SparseMatrixCSC, Matrix})\n\nCompute the L2 Norm of each row of M.\n\nExample\n\njulia> ma1 = [[1 2 3]; [-1 -2 -3]; [1 2 3]]\njulia> l2_rowwise(ma1)\n3×1 Matrix{Float64}:\n 3.7416573867739413\n 3.7416573867739413\n 3.7416573867739413\n\n\n\n\n\n","category":"method"},{"location":"helpers.html#JudiLingMeasures.make_measure_preparations-NTuple{6, Any}","page":"Helper Functions","title":"JudiLingMeasures.make_measure_preparations","text":"function make_measure_preparations(data_train, S_train, Shat_train,\n                                   res_learn_train, cue_obj_train,\n                                   rpi_learn_train)\n\nReturns all additional objects needed for measure calculations if the data of interest is the training data.\n\nArguments\n\ndata_train: The data for which the measures are to be calculated (training data).\nS_train: The semantic matrix of the training data\nShat_train: The predicted semantic matrix of the training data.\nres_learn_train: The first object return by the learn_paths_rpi algorithm for the training data.\ncue_obj_train: The cue object of the training data.\nrpi_learn_train: The second object return by the learn_paths_rpi algorithm for the training data.\n\nReturns\n\nresults::DataFrame: A deepcopy of data_train.\ncor_s::Matrix: Correlation matrix between Shat_train and S_train.\ndf::DataFrame: The output of res_learn_train (of the training data) in form of a dataframe\nrpi_df::DataFrame: Stores the path information about the predicted forms (from learn_paths), which is needed to compute things like PathSum, PathCounts and PathEntropies.\n\n\n\n\n\n","category":"method"},{"location":"helpers.html#JudiLingMeasures.make_measure_preparations-NTuple{8, Any}","page":"Helper Functions","title":"JudiLingMeasures.make_measure_preparations","text":"function make_measure_preparations(data_val, S_train, S_val, Shat_val,\n                                   res_learn_val, cue_obj_train, cue_obj_val,\n                                   rpi_learn_val)\n\nReturns all additional objects needed for measure calculations if the data of interest is the validation data.\n\nArguments\n\ndata_val: The data for which the measures are to be calculated (validation data).\nS_train: The semantic matrix of the training data\nS_val: The semantic matrix of the validation data\nShat_val: The predicted semantic matrix of the validation data.\nres_learn_val: The first object return by the learn_paths_rpi algorithm for the validation data.\ncue_obj_train: The cue object of the training data.\ncue_obj_val: The cue object of the data of interest.\nrpi_learn_val: The second object return by the learn_paths_rpi algorithm for the validation data.\n\nReturns\n\nresults::DataFrame: A deepcopy of data_val.\ncor_s::Matrix: Correlation matrix between Shat_val and S_val.\ndf::DataFrame: The output of res_learn_val (of the validation data) in form of a dataframe\nrpi_df::DataFrame: Stores the path information about the predicted forms (from learn_paths), which is needed to compute things like PathSum, PathCounts and PathEntropies.\n\n\n\n\n\n","category":"method"},{"location":"helpers.html#JudiLingMeasures.max_rowwise-Tuple{Union{SparseArrays.SparseMatrixCSC, Matrix}}","page":"Helper Functions","title":"JudiLingMeasures.max_rowwise","text":"max_rowwise(S::Union{JudiLing.SparseMatrixCSC, Matrix})\n\nGet the maximum of each row in S.\n\nExamples\n\njulia> ma1 = [[1 2 3]; [-1 -2 -3]; [1 2 3]]\njulia> max_rowwise(ma1)\n3×1 Matrix{Int64}:\n 3\n -1\n 3\n\n\n\n\n\n","category":"method"},{"location":"helpers.html#JudiLingMeasures.mean_rowwise-Tuple{Union{SparseArrays.SparseMatrixCSC, Matrix}}","page":"Helper Functions","title":"JudiLingMeasures.mean_rowwise","text":"mean_rowwise(S::Union{JudiLing.SparseMatrixCSC, Matrix})\n\nCalculate the mean of each row in S.\n\nExamples\n\njulia> ma1 = [[1 2 3]; [-1 -2 -3]; [1 2 3]]\njulia> mean_rowwise(ma1)\n3×1 Matrix{Float64}:\n  2.0\n -2.0\n  2.0\n\n\n\n\n\n","category":"method"},{"location":"helpers.html#JudiLingMeasures.safe_length-Tuple{Union{Missing, String}}","page":"Helper Functions","title":"JudiLingMeasures.safe_length","text":"safe_length(x::Union{Missing, String})\n\nCompute length of x, if x is missing return missing\n\nExample\n\njulia> safe_length(missing)\nmissing\njulia> safe_length(\"abc\")\n3\n\n\n\n\n\n","category":"method"},{"location":"helpers.html#JudiLingMeasures.safe_sum-Tuple{Union{Missing, Array}}","page":"Helper Functions","title":"JudiLingMeasures.safe_sum","text":"safe_sum(x::Array)\n\nCompute sum of all elements of x, if x is empty return missing\n\nExample\n\njulia> safe_sum([])\nmissing\njulia> safe_sum([1,2,3])\n6\n\n\n\n\n\n","category":"method"},{"location":"helpers.html#JudiLingMeasures.sem_density_mean-Tuple{Union{SparseArrays.SparseMatrixCSC, Matrix}, Int64}","page":"Helper Functions","title":"JudiLingMeasures.sem_density_mean","text":"sem_density_mean(s_cor::Union{JudiLing.SparseMatrixCSC, Matrix},\n                 n::Int)\n\nCompute the average semantic density of the predicted semantic vector with its n most correlated semantic neighbours.\n\nArguments\n\ns_cor::Union{JudiLing.SparseMatrixCSC, Matrix}: the correlation matrix between S and Shat\nn::Int: the number of highest semantic neighbours to take into account\n\nExample\n\njulia> ma2 = [[1 2 1 1]; [1 -2 3 1]; [1 -2 3 3]; [0 0 1 2]]\njulia> ma3 = [[-1 2 1 1]; [1 2 3 1]; [1 2 0 1]; [0.5 -2 1.5 0]]\njulia> cor_s = correlation_rowwise(ma2, ma3)\njulia> sem_density_mean(cor_s, 2)\n4-element Vector{Float64}:\n 0.7393813797301239\n 0.6420816485652429\n 0.4496869233815781\n 0.281150888376636\n\n\n\n\n\n","category":"method"}]
}
